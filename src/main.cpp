#include <iostream>
#include <boost/format.hpp>
#include <stdlib.h>
#include <random>

#include "utils.h"
#include "detector.h"
#include "tracker.h"
#include "counter.h"

using namespace std;

int main()
{
    string model_path = "./dnn_files/yolov5n6.onnx";
    Config config = {kMinConfidence, nmsThreshold, model_path, "./dnn_files/coco.names", cv::Size(640, 640), false};
    Detector detector(config);

    // Load a model.
    cv::dnn::Net net = cv::dnn::readNetFromONNX(model_path);

    // Create a window
    static const string kWinName = "Deep learning object detection in OpenCV";
    static const string trackingWin = "Tracking Window";
    // namedWindow(kWinName, cv::WINDOW_NORMAL);
    namedWindow(trackingWin, cv::WINDOW_NORMAL);

    // Open a video file or an image file or a camera stream.
    cv::VideoCapture cap;

    cap.open("./test_video/test_video.mp4");

    // Process frames.
    cv::Mat frame, tmpFrame;
    vector<cv::Rect> boxes;

    // Create SORT Tracker
    Tracker tracker;
    auto frame_index = 0;
    // bool count_preprocess = 0;
    
    //  std::vector<cv::Scalar> colors;
    // // Generate random colors to visualize different bbox
    // std::random_device rd;  //Will be used to obtain a seed for the random number engine
    // std::mt19937 gen(rd()); //Standard mersenne_twister_engine seeded with rd()
    // constexpr int max_random_value = 20;
    // std::uniform_int_distribution<> dis(0, max_random_value);
    // constexpr int factor = 255 / max_random_value;
    //
    // for (int n = 0; n < kNumColors; ++n) {
    //     //Use dis to transform the random unsigned int generated by gen into an int in [0, 7]
    //     colors.emplace_back(cv::Scalar(dis(gen) * factor, dis(gen) * factor, dis(gen) * factor));
    // }
    Colors cl = Colors();

    // Create Counter
    Counter counter;

    // Total Time Required
    cv::TickMeter totalTime;

    // Detection
    Detection detection;

    totalTime.start();
    while (true)
    {
        cap >> tmpFrame;

        if(tmpFrame.empty() == true)
        {
            totalTime.stop();
            std::cout << "Actual count : 239" << std::endl;
            std::cout << "Program count : " << to_string(counter.count) << std::endl;
            std::cout << "Accuracy : " << to_string((1 - (float) abs(237 - counter.count) / 237) * 100) << "%" << std::endl;
            float t = totalTime.getTimeSec();
            std::cout << "Total Time Taken : " << to_string(t) + "s" << std::endl;
            std::cout << "Inference Time : " << to_string(detection.inference) + "ms"<< std::endl;
            return 0;
        }
        if(frame_index == 0)
        {
            frame = tmpFrame;
            detection = detector.detect(frame);
            // boxes = detector.makeBoxes(frame, detection);

            boxes = detector.postProcess(frame, detection, cl);
            tracker.Run(boxes);
            const auto tracks = tracker.GetTracks();


            counter.setPadInfo(detection.info);
        }
        // Process every 2 frames for faster processing
        if(frame_index == 1)
        {
           frame = tmpFrame;

            // Cropping frame for better detection
            // frame = tmpFrame(cv::Range(100, tmpFrame.rows), cv::Range(0, tmpFrame.cols));
            // cv::Mat img_tracking = frame.clone();

            Detection detection = detector.detect(frame);
            boxes = detector.postProcess(frame, detection, cl);
            // boxes = detector.makeBoxes(detection);

            
            // for (auto &trk : tracks) {
            //     // only draw tracks which meet certain criteria
            //     if (trk.second.coast_cycles_ < kMaxCoastCycles &&
            //         (trk.second.hit_streak_ >= kMinHits || frame_index < kMinHits)) {
            //
            //         const auto &bbox = trk.second.GetStateAsBbox();
            //         cv::putText(img_tracking, std::to_string(trk.first), cv::Point(bbox.tl().x, bbox.tl().y - 10),
            //                     cv::FONT_HERSHEY_DUPLEX, 2, cv::Scalar(255, 255, 255), 2);
            //         cv::rectangle(img_tracking, bbox, colors[trk.first % kNumColors], 3);
            //     }
            // }
            frame_index = 0;

            tracker.Run(boxes);
            const auto tracks = tracker.GetTracks();
            counter.preprocess(frame);
            counter.process(frame, tracks, frame_index);
        }
        counter.postprocess(frame);
        frame_index++;

        imshow(trackingWin, frame);

        // imshow(kWinName, frame);
        cv::waitKey(60);
    }
}
